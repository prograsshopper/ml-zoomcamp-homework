{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82fea049-4fda-467a-9981-be0b89207fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f13d21f-7b1a-4d86-aaa0-9ce4abdc8e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"course_lead_scoring.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c1430e-311d-43fe-8e1d-31f7d82bd44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lead_source', 'industry', 'number_of_courses_viewed', 'annual_income',\n",
       "       'employment_status', 'location', 'interaction_count', 'lead_score',\n",
       "       'converted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23dce02f-59dd-4de5-ac19-799e394cb8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a47214a-3b28-4217-93bb-447ccf72ab96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the missing values are presented in the features.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efec5cf4-5e33-4008-a98f-118d2c4b43b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89b55495-65fc-4257-ba23-2eb8920e5af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lead_source', 'industry', 'employment_status', 'location']\n",
      "['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score', 'converted']\n"
     ]
    }
   ],
   "source": [
    "categorical = list(df.columns[df.dtypes == 'object'])\n",
    "numerical = list(df.columns[df.dtypes != 'object'])\n",
    "\n",
    "print(categorical)\n",
    "print(numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f641c90-0389-44e3-8847-43b3698b70a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If there are missing values:\n",
    "# For caterogiral features, replace them with 'NA'\n",
    "# For numerical features, replace with with 0.0\n",
    "\n",
    "for category in categorical:\n",
    "    df[category] = df[category].fillna('NA')\n",
    "\n",
    "for num in numerical:\n",
    "    df[num] = df[num].fillna(0.0)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6310a8f-bc8a-402e-ab69-0d8b5db6561a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "retail           203\n",
       "finance          200\n",
       "other            198\n",
       "healthcare       187\n",
       "education        187\n",
       "technology       179\n",
       "manufacturing    174\n",
       "NA               134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the most frequent observation (mode) for the column industry\n",
    "df.industry.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49913ec-4229-4a5e-9586-0dc5be3edf6f",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "- Create the correlation matrix for the numerical features of your dataset. In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "- What are the two features that have the biggest correlation?\n",
    "  - interaction_count and lead_score\n",
    "  - number_of_courses_viewed and lead_score\n",
    "  - number_of_courses_viewed and interaction_count\n",
    "  - annual_income and interaction_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "596c53fd-e320-47ef-933c-706653072a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interaction_count           0.009888\n",
       "number_of_courses_viewed   -0.004879\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interaction_count and lead_score\n",
    "# number_of_courses_viewed and lead_score\n",
    "df[['interaction_count', 'number_of_courses_viewed']].corrwith(df.lead_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "410edadd-10d4-47df-8c29-103294a979f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "annual_income               0.027036\n",
       "number_of_courses_viewed   -0.023565\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number_of_courses_viewed and interaction_count\n",
    "# annual_income and interaction_count\n",
    "df[['annual_income', 'number_of_courses_viewed']].corrwith(df.interaction_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407951f2-4e3d-4c08-81ef-d95ee0ac98e0",
   "metadata": {},
   "source": [
    "## Split the data\n",
    "- Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "- Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "- Make sure that the target value converted is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "182c13d6-16a7-4a08-b626-ce6e386738ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c15712b9-21d2-4b76-9d5f-eec4821e8b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(876, 293, 293)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "838732ad-d8f4-4bcd-a1b7-ba1700e85429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0a6c1e1-57fa-41c9-8db3-4c2bdae1f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.converted.values\n",
    "y_val = df_val.converted.values\n",
    "y_test = df_test.converted.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39ee79ba-b530-4e79-88a7-43df995550ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['converted']\n",
    "del df_val['converted']\n",
    "del df_test['converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e25d386b-5787-4912-afcd-64643a4d8b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24ed4e4a-83eb-4421-a195-1ad359602286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source          0.035396\n",
       "employment_status    0.012938\n",
       "industry             0.011575\n",
       "location             0.004464\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mutual information score between y and other categorical variables in the dataset. Use the training set only.\n",
    "# Round the scores to 2 decimals using round(score, 2).\n",
    "def mutual_info_converted(series):\n",
    "    return mutual_info_score(series, y_train)\n",
    "\n",
    "mi = df_train[categorical].apply(mutual_info_converted)\n",
    "mi.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd6f0e7-7698-468e-8ac8-e55ccea2c8a7",
   "metadata": {},
   "source": [
    "- Now let's train a logistic regression.\n",
    "- Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "- To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "- model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adc9476c-75ba-4b96-b28c-6fec31edfd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03aae6a4-b917-4e2d-9fb4-ab3047b0d0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val   = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc73e47d-928d-4718-a7be-95c17f2484a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.2220e+04, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n",
       "        3.0000e+00],\n",
       "       [5.9656e+04, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n",
       "        3.0000e+00],\n",
       "       [5.7134e+04, 0.0000e+00, 0.0000e+00, ..., 1.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00],\n",
       "       ...,\n",
       "       [7.4166e+04, 0.0000e+00, 1.0000e+00, ..., 0.0000e+00, 1.0000e+00,\n",
       "        1.0000e+00],\n",
       "       [3.9103e+04, 0.0000e+00, 0.0000e+00, ..., 0.0000e+00, 0.0000e+00,\n",
       "        2.0000e+00],\n",
       "       [4.7129e+04, 1.0000e+00, 0.0000e+00, ..., 0.0000e+00, 1.0000e+00,\n",
       "        1.0000e+00]], shape=(293, 31))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dicts   = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5c3807cf-fa3e-436c-b4fa-409d1eba6113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "274de54e-2639-42ae-a157-5887c277b2bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.6996587030716723), np.float64(0.7))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model on the training dataset.\n",
    "# To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "# model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "# Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "decision = (y_pred_proba >= 0.5).astype(int)\n",
    "(y_val == decision).mean(), round((y_val == decision).mean(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b8b21-6fba-4252-9cb9-1bcbb62c7631",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "- Let's find the least useful feature using the feature elimination technique.\n",
    "- Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "\n",
    "- Which of following feature has the smallest difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e98020b4-9572-45df-9f8c-cd4247b805d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = list(df.columns[df.dtypes == 'object'])\n",
    "numerical = [c for c in df_train.columns if c not in categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2c41ed3-b794-40f9-a972-82037d07611d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat industry - Accuracy: 0.6996587030716723, Diff: 0.0\n",
      "feat employment_status - Accuracy: 0.6962457337883959, Diff: 0.0034129692832763903\n",
      "feat lead_score - Accuracy: 0.7064846416382252, Diff: -0.0068259385665528916\n"
     ]
    }
   ],
   "source": [
    "original_accuracy =  (y_val == decision).mean()\n",
    "targets = ['industry','employment_status','lead_score']\n",
    "\n",
    "for feat in targets:\n",
    "    feats = [c for c in (categorical + numerical) if c != feat]\n",
    "    val_dicts   = df_val[feats].to_dict(orient='records')\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "    X_val   = dv.transform(val_dicts)\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    decision = (y_pred_proba >= 0.5).astype(int)\n",
    "    accuracy = (y_val == decision).mean()\n",
    "    print(f\"feat {feat} - Accuracy: {accuracy}, Diff: {original_accuracy - accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af601864-6791-4a3d-adc7-a4f69007c27a",
   "metadata": {},
   "source": [
    "- Now let's train a regularized logistic regression.\n",
    "- Let's try the following values of the parameter C: [0.01, 0.1, 1, 10, 100].\n",
    "- Train models using all the features as in Q4.\n",
    "- Calculate the accuracy on the validation dataset and round it to 3 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6211e4d1-f1bb-4fde-9ae4-de76109cdf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param 0.01 : 0.6997\n",
      "param 0.1 : 0.6997\n",
      "param 1 : 0.6997\n",
      "param 10 : 0.6997\n",
      "param 100 : 0.6997\n"
     ]
    }
   ],
   "source": [
    "categorical = list(df.columns[df.dtypes == 'object'])\n",
    "numerical = [c for c in df_train.columns if c not in categorical]\n",
    "\n",
    "for c in [0.01, 0.1, 1, 10, 100]:\n",
    "    train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(train_dicts)\n",
    "    val_dicts   = df_val[categorical + numerical].to_dict(orient='records')\n",
    "    X_val = dv.transform(val_dicts)\n",
    "    model = LogisticRegression(solver='liblinear', C=c, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    decision = (y_pred_proba >= 0.5).astype(int)\n",
    "    print(f\"param {c} : {round((y_val == decision).mean(), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b0b9f3-badb-4466-9583-3738143437f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoom-poetry",
   "language": "python",
   "name": "ml-zoom-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
